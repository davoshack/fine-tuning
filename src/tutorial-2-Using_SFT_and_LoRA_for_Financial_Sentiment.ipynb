{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Using SFT and LoRA for Financial Sentiment\n",
    "\n",
    "‚Ä¢ Find the  [Notebook](https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2010%20-%20FineTuning_a_LLM_Financial_Sentiment_CPU.ipynb)  for this section at  [towardsai.net/book](http://towardsai.net/book).\n",
    "\n",
    "We aim to fine-tune an LLM for conducting  **sentiment analysis on financial statements**. The LLM would categorize financial tweets as positive, negative, or neutral. The FinGPT project manages the dataset used in this tutorial. The dataset is a crucial element in this process.\n",
    "\n",
    "A detailed script for implementation and experimentation is included at the end of this chapter.\n",
    "\n",
    "In this tutorial, we‚Äôll fine-tune an LLM on a CPU. This is doable with some specific CPUs with optimizations specifically for common operations used in AI, such as Intel‚Äôs Xeon CPUs with the use of  [Intel Advanced Matrix Extensions](https://www.intel.com/content/www/us/en/products/docs/accelerator-engines/advanced-matrix-extensions/overview.html)  (AMX). For this tutorial, we create a Compute Engine virtual machine with 64 GB of RAM (as we‚Äôll fine-tune the model on CPU) and the previously mentioned CPUs. Both fine-tuning and inference can be accomplished by leveraging its optimization technologies.\n",
    "\n",
    "‚ö†Ô∏èIt‚Äôs important to be aware of the costs associated with virtual machines. The total cost will depend on the machine type and the instance‚Äôs uptime. Regularly check your costs in the billing section of GCP and spin off your instances when you don‚Äôt use them.\n",
    "\n",
    "üí°If you want to run the code in the section without spending much money, you can perform a few iterations of training on your virtual machine and then stop it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "The FinGPT sentiment dataset includes a collection of financial tweets and their associated labels. The dataset also features an instruction column, typically containing a prompt such as ‚ÄúWhat is the sentiment of the following content? Choose from Positive, Negative, or Neutral.‚Äù\n",
    "\n",
    "We use a smaller subset of the dataset from the Deep Lake database for practicality and efficiency, which already hosts the dataset on its hub.\n",
    "\n",
    "Use the `deeplake.load()` function to create the Dataset object and load the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "\n",
    "# Connect to the training and testing datasets\n",
    "ds = deeplake.load('hub://genai360/FingGPT-sentiment-train-set')\n",
    "ds_valid = deeplake.load('hub://genai360/FingGPT-sentiment-valid-set')\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Dataset(path='hub://genai360/FingGPT-sentiment-train-set', read_only=True, tensors=['input', 'instruction', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, develop a function to format a dataset sample into an appropriate input for the model. Unlike previous methods, this approach includes the instructions at the beginning of the prompt.\n",
    "\n",
    "The format is: `<instruction>\\n\\nContent: <tweet>\\n\\nSentiment: <sentiment>`. The placeholders within <> will be replaced with relevant values from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sample_text(example):\n",
    "    \"\"\"Prepare the text from a sample of the dataset.\"\"\"\n",
    "    text = f\"\"\"{example['instruction'].text()}\\n\\nContent: {example['input'].text()}\\n\\nSentiment: {example['output'].text()}\"\"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a formatted input derived from an entry in the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}  \n",
    "      \n",
    "    Content: Diageo Shares Surge on Report of Possible Takeover by Lemann  \n",
    "      \n",
    "    Sentiment: positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the [OPT-1.3B language model](https://huggingface.co/facebook/opt-1.3b) tokenizer and use the ConstantLengthDataset class to create the training and validation dataset. It aggregates multiple samples until a set sequence length threshold is met, improving the efficiency of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\")\n",
    "\n",
    "# Create the ConstantLengthDataset\n",
    "from trl.trainer import ConstantLengthDataset\n",
    "\n",
    "train_dataset = ConstantLengthDataset(\n",
    "    tokenizer,\n",
    "    ds,\n",
    "    formatting_func=prepare_sample_text,\n",
    "    infinite=True,\n",
    "    seq_length=1024\n",
    ")\n",
    "\n",
    "eval_dataset = ConstantLengthDataset(\n",
    "    tokenizer,\n",
    "    ds_valid,\n",
    "    formatting_func=prepare_sample_text,\n",
    "    seq_length=1024\n",
    ")\n",
    "\n",
    "# Show one sample from train set\n",
    "iterator = iter(train_dataset)\n",
    "sample = next(iterator)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    {'input_ids': tensor([50118, 35212, 8913, ..., 2430, 2, 2]),  \n",
    "    'labels': tensor([50118, 35212, 8913, ..., 2430, 2, 2])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí°Before launching the training process, execute the following code to reset the iterator pointer if the iterator is used to print a sample from the dataset: `train_dataset.start_iteration = 0`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mastering-fine-tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
